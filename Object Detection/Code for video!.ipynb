{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coefficient - run this first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dist = np.array([-0.53115401, 0.49380163, 0.02334731, 0.01249862, -0.19562481])\n",
    "mtx = np.array([[599.78448344, 0,             331.4887726 ],\n",
    "                [0,            595.3968694,   131.26905818],\n",
    "                [0,            0,                        1]])\n",
    "newcameramtx = np.array([[487.06121826,  0,            347.03125155],\n",
    "                         [0,             476.48925781, 142.04030917],\n",
    "                         [0,             0,            1           ]])\n",
    "roi = (19,32,608,302)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you need to notice?\n",
    "1. If the drone wont connect, just restart the kernel. The problem is the kernel\n",
    "2. Dont use function for 2 drone!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Content:\n",
    "1. Live streaming - 1 drone\n",
    "2. Live streaming - 2 drone\n",
    "3. Live streaming with undistorted image!\n",
    "4. Save video\n",
    "5. Save video with undistorted image - 1 drone!\n",
    "6. Save video with undistorted image - 2 drone! (run this for final result!)\n",
    "7. Drone capturing the image!\n",
    "8. Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Live streaming - 1 drone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cam = cv2.VideoCapture(\"tcp://192.168.1.1:5555\")\n",
    "running = True\n",
    "while running:\n",
    "    running, frame = cam.read()\n",
    "    if running:\n",
    "        cv2.imshow('frame', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == 27: #0xFF is representing binary. more detail:\n",
    "            # https://stackoverflow.com/questions/35372700/whats-0xff-for-in-cv2-waitkey1\n",
    "            running = False\n",
    "    else:\n",
    "        #error reading frame\n",
    "        print ('error reading video feed')\n",
    "\n",
    "cam.release() #Closes video file or capturing device.\n",
    "cv2.destroyAllWindows() #used to force all the open windows to close at once.\n",
    "# https://stackoverflow.com/questions/37713155/stream-video-from-drone-parrot-2-0-python-cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Live streaming - 2 drone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cam = cv2.VideoCapture(\"tcp://192.168.1.9:5555\")\n",
    "cam2 = cv2.VideoCapture(\"tcp://192.168.1.2:5555\")\n",
    "running = True\n",
    "running2 = True\n",
    "while running:\n",
    "    running, frame = cam.read()\n",
    "    running2, frame2 = cam2.read()\n",
    "    if running2:\n",
    "        cv2.imshow('frame2', frame2)\n",
    "        if cv2.waitKey(1) & 0xFF == 27: #0xFF is representing binary. more detail:\n",
    "            # https://stackoverflow.com/questions/35372700/whats-0xff-for-in-cv2-waitkey1\n",
    "            running2 = False\n",
    "    else:\n",
    "        #error reading frame\n",
    "        print ('error reading video1 feed')\n",
    "        \n",
    "    if running:\n",
    "        cv2.imshow('frame', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == 27: #0xFF is representing binary. more detail:\n",
    "            # https://stackoverflow.com/questions/35372700/whats-0xff-for-in-cv2-waitkey1\n",
    "            running = False\n",
    "    else:\n",
    "        #error reading frame\n",
    "        print ('error reading video2 feed')\n",
    "\n",
    "cam.release() #Closes video file or capturing device.\n",
    "cam2.release() #Closes video file or capturing device.\n",
    "cv2.destroyAllWindows() #used to force all the open windows to close at once.\n",
    "# https://stackoverflow.com/questions/37713155/stream-video-from-drone-parrot-2-0-python-cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Live streaming with undistorted image!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cam = cv2.VideoCapture(\"tcp://192.168.1.2:5555\")\n",
    "running = True\n",
    "while running:\n",
    "    running, frame = cam.read()\n",
    "    if running:\n",
    "        # undistort\n",
    "        dst = cv2.undistort(frame, mtx, dist, None, newcameramtx)\n",
    "        x, y, w, h = roi\n",
    "        dst = dst[y:y+h, x:x+w]\n",
    "        cv2.imshow('asd', dst)\n",
    "        if cv2.waitKey(1) & 0xFF == 27: \n",
    "            # escape key pressed \n",
    "            running = False\n",
    "    else:\n",
    "        # error reading frame\n",
    "        print ('error reading video feed')\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# https://stackoverflow.com/questions/37713155/stream-video-from-drone-parrot-2-0-python-cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The video was successfully saved\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "  \n",
    "# Create an object to read \n",
    "# from camera\n",
    "video = cv2.VideoCapture(\"tcp://192.168.1.9:5555\")\n",
    "   \n",
    "# We need to check if camera\n",
    "# is opened previously or not\n",
    "if (video.isOpened() == False): \n",
    "    print(\"Error reading video file\")\n",
    "\n",
    "# We need to set resolutions.\n",
    "# so, convert them from float to integer.\n",
    "frame_width = int(video.get(3)) #Width of the frames in the video stream.\n",
    "frame_height = int(video.get(4)) #Height of the frames in the video stream.\n",
    "   \n",
    "size = (frame_width, frame_height)\n",
    "   \n",
    "# Below VideoWriter object will create\n",
    "# a frame of above defined The output \n",
    "# is stored in 'filename.avi' file.\n",
    "result = cv2.VideoWriter('filename30.avi', \n",
    "                         cv2.VideoWriter_fourcc(*'MJPG'),\n",
    "                         30, size)\n",
    "    \n",
    "while(True):\n",
    "    ret, frame = video.read()\n",
    "  \n",
    "    if ret == True: \n",
    "  \n",
    "        # Write the frame into the\n",
    "        # file 'filename.avi'\n",
    "        result.write(frame)\n",
    "  \n",
    "        # Display the frame\n",
    "        # saved in the file\n",
    "        cv2.imshow('Frame', frame)\n",
    "  \n",
    "        # Press S on keyboard \n",
    "        # to stop the process\n",
    "        if cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "            break\n",
    "  \n",
    "    # Break the loop\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# When everything done, release \n",
    "# the video capture and video \n",
    "# write objects\n",
    "video.release()\n",
    "result.release()\n",
    "    \n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()\n",
    "   \n",
    "print(\"The video was successfully saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save video with undistorted image - 1 drone!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cam = cv2.VideoCapture(\"tcp://192.168.1.2:5555\")\n",
    "frame_width = int(cam.get(3)) #Width of the frames in the video stream.\n",
    "frame_height = int(cam.get(4)) #Height of the frames in the video stream.\n",
    "size = (frame_width, frame_height)\n",
    "result = cv2.VideoWriter('filetry9.avi', cv2.VideoWriter_fourcc(*'MJPG'), 30, size) \n",
    "#(fileoutput, code of codec used to compress the frames, fps, size of the videos)\n",
    "running = True\n",
    "while running:\n",
    "    running, frame = cam.read()\n",
    "    if running:\n",
    "        # undistort\n",
    "        dst = cv2.undistort(frame, mtx, dist, None, newcameramtx)\n",
    "        #you cannot crop this image! this is too hard to get done! \n",
    "        #x, y, w, h = roi\n",
    "        #dst = dst[y:y+h, x:x+w]\n",
    "        #size = (h, w)\n",
    "        #result = cv2.VideoWriter('filename2.avi', cv2.VideoWriter_fourcc(*'MJPG'), 10, size) \n",
    "        result.write(dst)\n",
    "        cv2.imshow('frame', dst)\n",
    "        if cv2.waitKey(1) & 0xFF == 27: \n",
    "            # escape key pressed \n",
    "            running = False\n",
    "    else:\n",
    "        # error reading frame\n",
    "        print ('error reading video feed')\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# https://stackoverflow.com/questions/37713155/stream-video-from-drone-parrot-2-0-python-cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save video with undistorted image - 2 drone!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "\n",
    "#variable\n",
    "ip1 = \"tcp://192.168.1.1:5555\"\n",
    "video1 = \"file1.avi\"\n",
    "ip2 = \"tcp://192.168.2.2:5555\"\n",
    "video2 = \"file2.avi\"\n",
    "running1 = True\n",
    "running2 = True\n",
    "\n",
    "#drone 1\n",
    "cam1 = cv2.VideoCapture(ip1)\n",
    "frame_width = int(cam1.get(3))\n",
    "frame_height = int(cam1.get(4))\n",
    "size1 = (frame_width, frame_height)\n",
    "result1 = cv2.VideoWriter(video1, cv2.VideoWriter_fourcc(*'MJPG'), 30, size1) \n",
    "\n",
    "#drone2\n",
    "cam2 = cv2.VideoCapture(ip2)\n",
    "frame_width = int(cam2.get(3))\n",
    "frame_height = int(cam2.get(4))\n",
    "size2 = (frame_width, frame_height)\n",
    "result2 = cv2.VideoWriter(video2, cv2.VideoWriter_fourcc(*'MJPG'), 30, size2) \n",
    "\n",
    "while running1:\n",
    "    running1, frame1 = cam1.read()\n",
    "    running2, frame2 = cam2.read()\n",
    "    \n",
    "    #drone 1\n",
    "    if running1:\n",
    "        dst1 = cv2.undistort(frame1, mtx, dist, None, newcameramtx)\n",
    "        result1.write(dst1)\n",
    "        cv2.imshow('frame1', dst1)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:  \n",
    "            running1 = False\n",
    "    else:\n",
    "        print ('error reading video1 feed')\n",
    "        \n",
    "    #drone 2\n",
    "    if running2:\n",
    "        dst2 = cv2.undistort(frame2, mtx, dist, None, newcameramtx)\n",
    "        result2.write(dst2)\n",
    "        cv2.imshow('frame2', dst2)\n",
    "        if cv2.waitKey(1) & 0xFF == 27: \n",
    "            running2 = False\n",
    "    else:\n",
    "        print ('error reading video2 feed')\n",
    "\n",
    "#shut all down\n",
    "cam1.release()\n",
    "cam2.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drone capturing the image!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image0.png written!\n",
      "image1.png written!\n",
      "image2.png written!\n",
      "image3.png written!\n",
      "image4.png written!\n",
      "image5.png written!\n",
      "image6.png written!\n",
      "image7.png written!\n",
      "image8.png written!\n",
      "image9.png written!\n",
      "image10.png written!\n",
      "image11.png written!\n",
      "image12.png written!\n",
      "image13.png written!\n",
      "image14.png written!\n",
      "image15.png written!\n",
      "image16.png written!\n",
      "image17.png written!\n",
      "image18.png written!\n",
      "image19.png written!\n",
      "image20.png written!\n",
      "image21.png written!\n",
      "image22.png written!\n",
      "image23.png written!\n",
      "image24.png written!\n",
      "image25.png written!\n",
      "image26.png written!\n",
      "image27.png written!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "cam = cv2.VideoCapture(\"tcp://192.168.1.1:5555\")\n",
    "\n",
    "cv2.namedWindow(\"test\")\n",
    "\n",
    "img_counter = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    dst = cv2.undistort(frame, mtx, dist, None, newcameramtx)\n",
    "    if not ret:\n",
    "        print(\"failed to grab frame\")\n",
    "        break\n",
    "    cv2.imshow(\"test\", dst)\n",
    "\n",
    "    k = cv2.waitKey(1)\n",
    "    if k%256 == 27:\n",
    "        # ESC pressed\n",
    "        print(\"Escape hit, closing...\")\n",
    "        break\n",
    "    elif k%256 == 32:\n",
    "        # SPACE pressed\n",
    "        img_name = \"image{}.png\".format(img_counter)\n",
    "        cv2.imwrite(img_name, dst)\n",
    "        print(\"{} written!\".format(img_name))\n",
    "        img_counter += 1 \n",
    "\n",
    "cam.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import argparse\n",
    "\n",
    "# termination criteria\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "def calibrate(dirpath, prefix, image_format, square_size, width=9, height=6):\n",
    "    \"\"\" Apply camera calibration operation for images in the given directory path. \"\"\"\n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(8,6,0)\n",
    "    objp = np.zeros((height*width, 3), np.float32)\n",
    "    objp[:, :2] = np.mgrid[0:width, 0:height].T.reshape(-1, 2)\n",
    "\n",
    "    objp = objp * square_size\n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = []  # 3d point in real world space\n",
    "    imgpoints = []  # 2d points in image plane.\n",
    "\n",
    "    #if dirpath[-1:] == '/':\n",
    "    #    dirpath = dirpath[:-1]\n",
    "\n",
    "    #images = glob.glob(dirpath+'/' + prefix + '*.' + image_format)\n",
    "    images = glob.glob('*.png')\n",
    "    for fname in images:\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find the chess board corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (width, height), None)\n",
    "\n",
    "        # If found, add object points, image points (after refining them)\n",
    "        if ret:\n",
    "            objpoints.append(objp)\n",
    "\n",
    "            corners2 = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)\n",
    "            imgpoints.append(corners2)\n",
    "\n",
    "            # Draw and display the corners\n",
    "            img = cv2.drawChessboardCorners(img, (width, height), corners2, ret)\n",
    "\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "    return [ret, mtx, dist, rvecs, tvecs]\n",
    "\n",
    "def save_coefficients(mtx, dist, path):\n",
    "    \"\"\" Save the camera matrix and the distortion coefficients to given path/file. \"\"\"\n",
    "    cv_file = cv2.FileStorage(path, cv2.FILE_STORAGE_WRITE)\n",
    "    cv_file.write(\"K\", mtx)\n",
    "    cv_file.write(\"D\", dist)\n",
    "    # note you *release* you don't close() a FileStorage object\n",
    "    cv_file.release()\n",
    "def load_coefficients(path):\n",
    "    \"\"\" Loads camera matrix and distortion coefficients. \"\"\"\n",
    "    # FILE_STORAGE_READ\n",
    "    cv_file = cv2.FileStorage(path, cv2.FILE_STORAGE_READ)\n",
    "\n",
    "    # note we also have to specify the type to retrieve other wise we only get a\n",
    "    # FileNode object back instead of a matrix\n",
    "    camera_matrix = cv_file.getNode(\"K\").mat()\n",
    "    dist_matrix = cv_file.getNode(\"D\").mat()\n",
    "\n",
    "    cv_file.release()\n",
    "    return [camera_matrix, dist_matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'gray' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-4c1c79da21e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvecs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtvecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalibrate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\\\Users\\\\halim\\\\image_drone'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'image'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'.png'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0285\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msave_coefficients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"C:\\\\Users\\\\halim\\\\image_drone\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Calibration is finished. RMS: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-48b16222eed1>\u001b[0m in \u001b[0;36mcalibrate\u001b[1;34m(dirpath, prefix, image_format, square_size, width, height)\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrawChessboardCorners\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorners2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvecs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtvecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalibrateCamera\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjpoints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgpoints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvecs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtvecs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'gray' referenced before assignment"
     ]
    }
   ],
   "source": [
    "ret, mtx, dist, rvecs, tvecs = calibrate(r'C:\\\\Users\\\\halim\\\\image_drone', 'image', '.png', 0.0285, 9, 6)\n",
    "save_coefficients(mtx, dist, \"C:\\\\Users\\\\halim\\\\image_drone\")\n",
    "print(\"Calibration is finished. RMS: \", ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\halim'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\halim\\image_drone\n"
     ]
    }
   ],
   "source": [
    "%cd image_drone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#note that you should in this folder: C:\\Users\\halim\\image_drone\n",
    "\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import glob\n",
    "# termination criteria, you could read more from this documentation: \n",
    "# https://docs.opencv.org/master/d1/d5c/tutorial_py_kmeans_opencv.html\n",
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32) # np.float32 is dtype\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2) # print the statement to know what is the list look like!\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "images = glob.glob('*.png')\n",
    "\n",
    "for fname in images:\n",
    "    img = cv.imread(fname)\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Find the chess board corners\n",
    "    ret, corners = cv.findChessboardCorners(gray, (9,6), None) # ret return true/false, corners return array of detected corner!\n",
    "    \n",
    "    # If found, add object points, image points (after refining them)\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        corners2 = cv.cornerSubPix(gray,corners, (11,11), (-1,-1), criteria)\n",
    "        imgpoints.append(corners)\n",
    "        # Draw and display the corners\n",
    "        cv.drawChessboardCorners(img, (9,6), corners2, ret)\n",
    "        cv.imshow('img', img)\n",
    "        cv.waitKey(100)\n",
    "        \n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, mtx, dist, rvecs, tvecs = cv.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None) \n",
    "# '::' is slice operator or double colon\n",
    "# mtx: camera matrix\n",
    "# dist: distortion coefficient\n",
    "# rvecs: Rotation specified as a 3×1 vector. The direction of the vector specifies the axis of rotation and \n",
    "# the magnitude of the vector specifies the angle of rotation.\n",
    "# tvecs: 3×1 Translation vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('image14.png')\n",
    "h,  w = img.shape[:2]\n",
    "newcameramtx, roi = cv.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[485.42697144   0.         347.72173202]\n",
      " [  0.         474.4822998  142.69650144]\n",
      " [  0.           0.           1.        ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(newcameramtx)\n",
    "type(newcameramtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# undistort\n",
    "dst = cv.undistort(img, mtx, dist, None, newcameramtx)\n",
    "\n",
    "# crop the image\n",
    "x, y, w, h = roi\n",
    "dst = dst[y:y+h, x:x+w]\n",
    "cv.imwrite('calibresult14.png', dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[597.96627927   0.         331.83495852]\n",
      " [  0.         593.5337345  131.95205793]\n",
      " [  0.           0.           1.        ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(mtx)\n",
    "type(mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.52701693  0.4863632   0.02308924  0.01268769 -0.19184978]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dist)\n",
    "type(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3 4 5]\n",
      " [1 2 3 4 6]]\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([[1, 2, 3, 4, 5],\n",
    "               [1, 2, 3, 4, 6]])\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.25280196],\n",
      "       [0.22280366],\n",
      "       [0.08984669]]), array([[-0.07756096],\n",
      "       [-0.18281396],\n",
      "       [-0.04744307]]), array([[-0.04268799],\n",
      "       [-0.62026204],\n",
      "       [-0.07860496]]), array([[ 0.1473003 ],\n",
      "       [-0.20021497],\n",
      "       [-0.01994438]]), array([[-0.68423568],\n",
      "       [-0.11494423],\n",
      "       [-0.16182662]]), array([[ 0.77355986],\n",
      "       [-0.03222733],\n",
      "       [ 0.02457107]]), array([[ 0.40754934],\n",
      "       [ 0.16427036],\n",
      "       [-0.07085233]]), array([[0.17327927],\n",
      "       [0.23902886],\n",
      "       [0.0840339 ]]), array([[ 0.31436626],\n",
      "       [-0.29881281],\n",
      "       [ 0.07876738]]), array([[ 0.30495881],\n",
      "       [-0.35823833],\n",
      "       [ 0.15254668]]), array([[ 0.30175479],\n",
      "       [-0.36273556],\n",
      "       [ 0.15699541]]), array([[-0.02298643],\n",
      "       [ 0.00943021],\n",
      "       [ 0.09487979]]), array([[-0.35732899],\n",
      "       [ 0.08383856],\n",
      "       [ 0.25870875]]), array([[-0.04126391],\n",
      "       [-0.07900856],\n",
      "       [-0.10865033]]), array([[-0.01067061],\n",
      "       [ 0.48536285],\n",
      "       [-0.1273099 ]]), array([[ 0.04260464],\n",
      "       [-0.71699975],\n",
      "       [-0.11858629]]), array([[ 0.49368987],\n",
      "       [-0.03877768],\n",
      "       [-0.12994099]]), array([[ 0.21649959],\n",
      "       [-0.35017671],\n",
      "       [-0.03844117]]), array([[0.19803116],\n",
      "       [0.0250494 ],\n",
      "       [0.22429875]]), array([[0.18644447],\n",
      "       [0.06582902],\n",
      "       [0.14595007]]), array([[0.05691705],\n",
      "       [0.07245228],\n",
      "       [0.0296109 ]])]\n"
     ]
    }
   ],
   "source": [
    "print (rvecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.1) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-kh7iq4w7\\opencv\\modules\\highgui\\src\\window.cpp:376: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-f29751f1b052>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mimg_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbytearray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mURL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_arr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'IPWebcam'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.1) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-kh7iq4w7\\opencv\\modules\\highgui\\src\\window.cpp:376: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "  \n",
    "# Replace the below URL with your own. Make sure to add \"/shot.jpg\" at last.\n",
    "url = \"http://192.168.0.103:8080/shot.jpg\"\n",
    "  \n",
    "# While loop to continuously fetching data from the Url\n",
    "while True:\n",
    "    img_resp = requests.get(url)\n",
    "    img_arr = np.array(bytearray(img_resp.content), dtype=np.uint8)\n",
    "    img = cv2.imdecode(img_arr, -1)\n",
    "    img = imutils.resize(img, width=1000, height=1800)\n",
    "    cv2.imshow(\"Android_cam\", img)\n",
    "  \n",
    "    # Press Esc key to exit\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "  \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "a = ['1','2','3']\n",
    "\n",
    "for x in a:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<__main__.Obstacle object at 0x0000020D9480C310>, <__main__.Obstacle object at 0x0000020D9480C8E0>]\n"
     ]
    }
   ],
   "source": [
    "class Obstacle(object):\n",
    "    def __init__(self, position):\n",
    "        self.position = position\n",
    "        self.positionHistory = [position]\n",
    "        self.ObstaclePotentialForces = []\n",
    "\n",
    "Obstacles = []\n",
    "Coral = Obstacle((0, 60, 50))\n",
    "Coral2 = Obstacle((0, 50, 50))\n",
    "Obstacles.append(Coral)\n",
    "Obstacles.append(Coral2)\n",
    "\n",
    "print(Obstacles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1', '2', '3']]\n",
      "[['3', '3', '3']]\n"
     ]
    }
   ],
   "source": [
    "position = ['1','2','3']\n",
    "history = [position]\n",
    "print(history)\n",
    "position = ['3','3','3']\n",
    "history = [position]\n",
    "print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'apf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-5aebaacd5bbc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mDrone1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mDrone1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"1\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mDrone1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'apf'"
     ]
    }
   ],
   "source": [
    "Drone1 = (0, (0, 5, 4), 1)\n",
    "Drone1.apf = \"1\"\n",
    "print (Drone1.apf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "thres = 0.45 # Threshold to detect object\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3,1280)\n",
    "cap.set(4,720)\n",
    "cap.set(10,70)\n",
    "\n",
    "classNames= []\n",
    "classFile = 'coco.names'\n",
    "with open(classFile,'rt') as f:\n",
    "    classNames=[line.rstrip() for line in f]\n",
    "\n",
    "configPath = 'ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt'\n",
    "weightsPath = 'frozen_inference_graph.pb'\n",
    "\n",
    "net = cv2.dnn_DetectionModel(weightsPath,configPath)\n",
    "net.setInputSize(320,320)\n",
    "net.setInputScale(1.0/ 127.5)\n",
    "net.setInputMean((127.5, 127.5, 127.5))\n",
    "net.setInputSwapRB(True)\n",
    "\n",
    "while True:\n",
    "    success,img = cap.read()\n",
    "    classIds, confs, bbox = net.detect(img,confThreshold=thres)\n",
    "    print(classIds,bbox)\n",
    "\n",
    "    if len(classIds) != 0:\n",
    "        for classId, confidence,box in zip(classIds.flatten(),confs.flatten(),bbox):\n",
    "            cv2.rectangle(img,box,color=(0,255,0),thickness=2)\n",
    "            cv2.putText(img,classNames[classId-1].upper(),(box[0]+10,box[1]+30),\n",
    "            cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "            cv2.putText(img,str(round(confidence*100,2)),(box[0]+200,box[1]+30),\n",
    "            cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "\n",
    "    cv2.imshow(\"Output\",img)\n",
    "    cv2.waitKey(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
